# ml/utils.py

def pipe_tokenizer(text):
    return text.split('|')
